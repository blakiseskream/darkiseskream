% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kitchen-sink.R
\name{sdf_write_and_save_table}
\alias{sdf_write_and_save_table}
\title{use the Spark API to write a dataframe as a Hive table with optional file format and path params. Works with Spark 2.0 w/ Hive.}
\usage{
sdf_write_and_save_table(tbl, table_name, format = "orc",
  mode = "overwrite", path = NULL)
}
\arguments{
\item{tbl}{a spark dataframe or dplyr tbl, to be passed into \code{spark_dataframe()} call}

\item{table_name}{the name of the table for hive metastore. For database specific use the format \code{dbname.table_name}}

\item{format}{the file format to save as, defaults as orc. For more details see the \href{https://spark.apache.org/docs/latest/sql-programming-guide.html#generic-loadsave-functions}{Spark docs}}

\item{mode}{the write mode, defaults to 'overwrite'. Can also take, 'append', 'ignore', and 'error.' For more details see the \href{https://spark.apache.org/docs/latest/sql-programming-guide.html#generic-loadsave-functions}{Spark docs}}

\item{path}{optional character string. the path to save the file to, e.g. "s3://my_bucket/iris/"}
}
\description{
This function mimics a series of Spark API calls in the format of \code{df.write.format('format').mode('mode').option('path','path://').saveAsTable('table_name')}
This allows a user to save a spark dataframe to Hive by not only writing it to a specific path in a specific format but also saving it to Hive metastore.
For more details see the \href{https://spark.apache.org/docs/latest/sql-programming-guide.html#generic-loadsave-functions}{Spark docs} on loading and saving tables

You can choose to chain further commands afer this function with the format sdf_
}
